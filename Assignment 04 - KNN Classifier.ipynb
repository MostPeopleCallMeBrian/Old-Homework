{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2 - KNN Classifier\n",
    "#Brian Conway\n",
    "#Worked on alone this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Q1. What is the purpose of the %matplotlib inline command?\n",
    "Answer: The inline command enables inline plotting, so that graphs and plots will be displayed neatly below the cell in Jupyter Notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
       "        [4.9, 3. , 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.3, 0.2],\n",
       "        [4.6, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.6, 1.4, 0.2],\n",
       "        [5.4, 3.9, 1.7, 0.4],\n",
       "        [4.6, 3.4, 1.4, 0.3],\n",
       "        [5. , 3.4, 1.5, 0.2],\n",
       "        [4.4, 2.9, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.1],\n",
       "        [5.4, 3.7, 1.5, 0.2],\n",
       "        [4.8, 3.4, 1.6, 0.2],\n",
       "        [4.8, 3. , 1.4, 0.1],\n",
       "        [4.3, 3. , 1.1, 0.1],\n",
       "        [5.8, 4. , 1.2, 0.2],\n",
       "        [5.7, 4.4, 1.5, 0.4],\n",
       "        [5.4, 3.9, 1.3, 0.4],\n",
       "        [5.1, 3.5, 1.4, 0.3],\n",
       "        [5.7, 3.8, 1.7, 0.3],\n",
       "        [5.1, 3.8, 1.5, 0.3],\n",
       "        [5.4, 3.4, 1.7, 0.2],\n",
       "        [5.1, 3.7, 1.5, 0.4],\n",
       "        [4.6, 3.6, 1. , 0.2],\n",
       "        [5.1, 3.3, 1.7, 0.5],\n",
       "        [4.8, 3.4, 1.9, 0.2],\n",
       "        [5. , 3. , 1.6, 0.2],\n",
       "        [5. , 3.4, 1.6, 0.4],\n",
       "        [5.2, 3.5, 1.5, 0.2],\n",
       "        [5.2, 3.4, 1.4, 0.2],\n",
       "        [4.7, 3.2, 1.6, 0.2],\n",
       "        [4.8, 3.1, 1.6, 0.2],\n",
       "        [5.4, 3.4, 1.5, 0.4],\n",
       "        [5.2, 4.1, 1.5, 0.1],\n",
       "        [5.5, 4.2, 1.4, 0.2],\n",
       "        [4.9, 3.1, 1.5, 0.2],\n",
       "        [5. , 3.2, 1.2, 0.2],\n",
       "        [5.5, 3.5, 1.3, 0.2],\n",
       "        [4.9, 3.6, 1.4, 0.1],\n",
       "        [4.4, 3. , 1.3, 0.2],\n",
       "        [5.1, 3.4, 1.5, 0.2],\n",
       "        [5. , 3.5, 1.3, 0.3],\n",
       "        [4.5, 2.3, 1.3, 0.3],\n",
       "        [4.4, 3.2, 1.3, 0.2],\n",
       "        [5. , 3.5, 1.6, 0.6],\n",
       "        [5.1, 3.8, 1.9, 0.4],\n",
       "        [4.8, 3. , 1.4, 0.3],\n",
       "        [5.1, 3.8, 1.6, 0.2],\n",
       "        [4.6, 3.2, 1.4, 0.2],\n",
       "        [5.3, 3.7, 1.5, 0.2],\n",
       "        [5. , 3.3, 1.4, 0.2],\n",
       "        [7. , 3.2, 4.7, 1.4],\n",
       "        [6.4, 3.2, 4.5, 1.5],\n",
       "        [6.9, 3.1, 4.9, 1.5],\n",
       "        [5.5, 2.3, 4. , 1.3],\n",
       "        [6.5, 2.8, 4.6, 1.5],\n",
       "        [5.7, 2.8, 4.5, 1.3],\n",
       "        [6.3, 3.3, 4.7, 1.6],\n",
       "        [4.9, 2.4, 3.3, 1. ],\n",
       "        [6.6, 2.9, 4.6, 1.3],\n",
       "        [5.2, 2.7, 3.9, 1.4],\n",
       "        [5. , 2. , 3.5, 1. ],\n",
       "        [5.9, 3. , 4.2, 1.5],\n",
       "        [6. , 2.2, 4. , 1. ],\n",
       "        [6.1, 2.9, 4.7, 1.4],\n",
       "        [5.6, 2.9, 3.6, 1.3],\n",
       "        [6.7, 3.1, 4.4, 1.4],\n",
       "        [5.6, 3. , 4.5, 1.5],\n",
       "        [5.8, 2.7, 4.1, 1. ],\n",
       "        [6.2, 2.2, 4.5, 1.5],\n",
       "        [5.6, 2.5, 3.9, 1.1],\n",
       "        [5.9, 3.2, 4.8, 1.8],\n",
       "        [6.1, 2.8, 4. , 1.3],\n",
       "        [6.3, 2.5, 4.9, 1.5],\n",
       "        [6.1, 2.8, 4.7, 1.2],\n",
       "        [6.4, 2.9, 4.3, 1.3],\n",
       "        [6.6, 3. , 4.4, 1.4],\n",
       "        [6.8, 2.8, 4.8, 1.4],\n",
       "        [6.7, 3. , 5. , 1.7],\n",
       "        [6. , 2.9, 4.5, 1.5],\n",
       "        [5.7, 2.6, 3.5, 1. ],\n",
       "        [5.5, 2.4, 3.8, 1.1],\n",
       "        [5.5, 2.4, 3.7, 1. ],\n",
       "        [5.8, 2.7, 3.9, 1.2],\n",
       "        [6. , 2.7, 5.1, 1.6],\n",
       "        [5.4, 3. , 4.5, 1.5],\n",
       "        [6. , 3.4, 4.5, 1.6],\n",
       "        [6.7, 3.1, 4.7, 1.5],\n",
       "        [6.3, 2.3, 4.4, 1.3],\n",
       "        [5.6, 3. , 4.1, 1.3],\n",
       "        [5.5, 2.5, 4. , 1.3],\n",
       "        [5.5, 2.6, 4.4, 1.2],\n",
       "        [6.1, 3. , 4.6, 1.4],\n",
       "        [5.8, 2.6, 4. , 1.2],\n",
       "        [5. , 2.3, 3.3, 1. ],\n",
       "        [5.6, 2.7, 4.2, 1.3],\n",
       "        [5.7, 3. , 4.2, 1.2],\n",
       "        [5.7, 2.9, 4.2, 1.3],\n",
       "        [6.2, 2.9, 4.3, 1.3],\n",
       "        [5.1, 2.5, 3. , 1.1],\n",
       "        [5.7, 2.8, 4.1, 1.3],\n",
       "        [6.3, 3.3, 6. , 2.5],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [7.1, 3. , 5.9, 2.1],\n",
       "        [6.3, 2.9, 5.6, 1.8],\n",
       "        [6.5, 3. , 5.8, 2.2],\n",
       "        [7.6, 3. , 6.6, 2.1],\n",
       "        [4.9, 2.5, 4.5, 1.7],\n",
       "        [7.3, 2.9, 6.3, 1.8],\n",
       "        [6.7, 2.5, 5.8, 1.8],\n",
       "        [7.2, 3.6, 6.1, 2.5],\n",
       "        [6.5, 3.2, 5.1, 2. ],\n",
       "        [6.4, 2.7, 5.3, 1.9],\n",
       "        [6.8, 3. , 5.5, 2.1],\n",
       "        [5.7, 2.5, 5. , 2. ],\n",
       "        [5.8, 2.8, 5.1, 2.4],\n",
       "        [6.4, 3.2, 5.3, 2.3],\n",
       "        [6.5, 3. , 5.5, 1.8],\n",
       "        [7.7, 3.8, 6.7, 2.2],\n",
       "        [7.7, 2.6, 6.9, 2.3],\n",
       "        [6. , 2.2, 5. , 1.5],\n",
       "        [6.9, 3.2, 5.7, 2.3],\n",
       "        [5.6, 2.8, 4.9, 2. ],\n",
       "        [7.7, 2.8, 6.7, 2. ],\n",
       "        [6.3, 2.7, 4.9, 1.8],\n",
       "        [6.7, 3.3, 5.7, 2.1],\n",
       "        [7.2, 3.2, 6. , 1.8],\n",
       "        [6.2, 2.8, 4.8, 1.8],\n",
       "        [6.1, 3. , 4.9, 1.8],\n",
       "        [6.4, 2.8, 5.6, 2.1],\n",
       "        [7.2, 3. , 5.8, 1.6],\n",
       "        [7.4, 2.8, 6.1, 1.9],\n",
       "        [7.9, 3.8, 6.4, 2. ],\n",
       "        [6.4, 2.8, 5.6, 2.2],\n",
       "        [6.3, 2.8, 5.1, 1.5],\n",
       "        [6.1, 2.6, 5.6, 1.4],\n",
       "        [7.7, 3. , 6.1, 2.3],\n",
       "        [6.3, 3.4, 5.6, 2.4],\n",
       "        [6.4, 3.1, 5.5, 1.8],\n",
       "        [6. , 3. , 4.8, 1.8],\n",
       "        [6.9, 3.1, 5.4, 2.1],\n",
       "        [6.7, 3.1, 5.6, 2.4],\n",
       "        [6.9, 3.1, 5.1, 2.3],\n",
       "        [5.8, 2.7, 5.1, 1.9],\n",
       "        [6.8, 3.2, 5.9, 2.3],\n",
       "        [6.7, 3.3, 5.7, 2.5],\n",
       "        [6.7, 3. , 5.2, 2.3],\n",
       "        [6.3, 2.5, 5. , 1.9],\n",
       "        [6.5, 3. , 5.2, 2. ],\n",
       "        [6.2, 3.4, 5.4, 2.3],\n",
       "        [5.9, 3. , 5.1, 1.8]]),\n",
       " 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "        2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]),\n",
       " 'frame': None,\n",
       " 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'),\n",
       " 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...',\n",
       " 'feature_names': ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " 'filename': 'C:\\\\Users\\\\Phillip\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q2. import iris dataset Use load_iris function from sklearn.datasets module\n",
    "#display data\n",
    "#Some needed imports, and loading the iris dataset in as 'data'\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "data=load_iris()\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.utils.Bunch"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q3. Display the type of iris data\n",
    "#just the built in python type() command\n",
    "type(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q4. print details of dataset. \n",
    "#use the DESCR function of sklearn to print details\n",
    "data.DESCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'C:\\\\Users\\\\Phillip\\\\anaconda3\\\\lib\\\\site-packages\\\\sklearn\\\\datasets\\\\data\\\\iris.csv'}\n"
     ]
    }
   ],
   "source": [
    "#Q5: Display the samples in iris data \n",
    "#This is just printing the data itself\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "['setosa' 'versicolor' 'virginica']\n"
     ]
    }
   ],
   "source": [
    "#Q6. Print the following: feature names, targets and target names\n",
    "#all data.field\n",
    "print(data.feature_names)\n",
    "print(data.target)\n",
    "print(data.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#Q7. Display the types of the features and response\n",
    "#perhaps data was a bad name for our iris information cuz now we have to use the type function on data.data\n",
    "print(type(data.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the Sample and Target Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations:\n",
      "150\n",
      "Number of features:\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#Q8. Disply number of samples and features in the datase\n",
    "#(first dimension = number of observations, second dimensions = number of features)\n",
    "#data.target is the number classified samples, len() on that will be the number of observations\n",
    "#len() of feature_names is logically the number of features\n",
    "print('Number of observations:')\n",
    "print(len(data.target))\n",
    "print('Number of features:')\n",
    "print(len(data.feature_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "#Q9. Dispay number of target values(response)\n",
    "#len() of target names, in other words\n",
    "print(len(data.target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the Data for Training and Testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10: Prepare data by splitting into Training and Testing (70% Training and 30% Testing)\n",
    "#test train split, a well known line of code\n",
    "x,y=data.data, data.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(x,y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Set Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "105\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "#Q11: Display Training and Testing Set Sizes\n",
    "#two more prints of the len() function\n",
    "print(len(y_train))\n",
    "print(len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q12: Use KNeighborsClassifier estimator to create the model \n",
    "model=KNeighborsClassifier()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q13: Train the model\n",
    "#model.fit on the training data \n",
    "model.fit(X=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting Digit Classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 1 0 0 2 2 1 1 2 1 2 0 1 1 0 2 2 1 2 1 1 2 2 2 1 1 1 0 2 0 1 0 0 1 1 1 2\n",
      " 0 2 0 2 0 2 1 2]\n"
     ]
    }
   ],
   "source": [
    "#Q14: Report your prodictions\n",
    "#model.predict on the X_test data, remember y_test is the actual results\n",
    "predicted=model.predict(X_test)\n",
    "print(predicted)\n",
    "#go ahead and set the expected, actual values to the y_test cuz we'll use it in a bit.\n",
    "expected=y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(//complete this code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimator Method `score`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "#Q15: Print the score\n",
    "accuracy= metrics.accuracy_score(predicted,expected)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11,  0,  0],\n",
       "       [ 0, 16,  1],\n",
       "       [ 0,  2, 15]], dtype=int64)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q16: Print confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#import the confusion matrix and print it\n",
    "confusion=confusion_matrix(predicted, expected)\n",
    "confusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      setosa       1.00      1.00      1.00        11\n",
      "  versicolor       0.94      0.89      0.91        18\n",
      "   virginica       0.88      0.94      0.91        16\n",
      "\n",
      "    accuracy                           0.93        45\n",
      "   macro avg       0.94      0.94      0.94        45\n",
      "weighted avg       0.93      0.93      0.93        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Q17: report classification\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Calling another function from the sklearnmetrics library\n",
    "print(classification_report(expected, predicted, target_names=data.target_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x26ec2a8a970>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Q18: Visualize confusion matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "#output the confusion matrix but this time as a heat map\n",
    "#I'm a little mesmerized by  the colors\n",
    "plot_confusion_matrix(model, X_test, y_test)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold Cross-Validation (KFold object) and cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q19: Perform K-Fold Cross-validation with different k values. \n",
    "from sklearn.model_selection import KFold #module for doing kFold\n",
    "\n",
    "#kfold, with 10 splits, a random state of the answer to everything, and shuffled\n",
    "kFold= KFold(n_splits=10, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.        , 1.        , 1.        , 1.        ,\n",
       "       0.93333333, 0.86666667, 1.        , 1.        , 0.93333333])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#Score of each cross fold validation, essentially 10 more training using the entire data set for testing and training\n",
    "scores= cross_val_score(estimator=model, X=data.data, y=data.target, cv=kFold)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9466666666666667, 0.9666666666666667, 0.966394025604552, 0.9733333333333334, 0.9733333333333333, 0.966295609152752, 0.9733187134502924, 0.9730392156862746, 0.9733333333333334, 0.9730269730269732, 0.9722222222222222, 0.9720279720279719, 0.9733766233766233, 0.9733333333333334, 0.9722222222222223, 0.9730392156862746, 0.9652777777777778, 0.9727443609022557, 0.9642857142857144, 0.9659863945578232, 0.972943722943723, 0.963768115942029, 0.9652777777777778, 0.9666666666666666, 0.9666666666666667, 0.9641975308641976, 0.9642857142857144, 0.9655172413793105, 0.9666666666666668, 0.9661290322580646, 0.9671875000000001, 0.9636363636363636, 0.9632352941176471, 0.9642857142857143, 0.9652777777777778, 0.9662162162162162, 0.9649122807017543, 0.9658119658119657, 0.9666666666666666, 0.9674796747967479, 0.9642857142857143, 0.9612403100775194, 0.9621212121212122, 0.962962962962963, 0.963768115942029, 0.9645390070921986, 0.9652777777777778, 0.965986394557823, 0.9666666666666666, 0.9640522875816993, 0.9647435897435896, 0.9654088050314465, 0.9660493827160493, 0.9666666666666667, 0.9672619047619048, 0.9678362573099415, 0.9655172413793104, 0.9632768361581922, 0.9611111111111111, 0.9590163934426229, 0.9596774193548387, 0.9603174603174603, 0.9609375, 0.9615384615384616, 0.9621212121212122, 0.9626865671641791, 0.9632352941176471, 0.9637681159420289, 0.9642857142857143, 0.9647887323943662, 0.9652777777777778, 0.9657534246575342, 0.9662162162162162, 0.9666666666666667, 0.9671052631578947, 0.961038961038961, 0.9615384615384616, 0.9620253164556962, 0.9625, 0.9629629629629629, 0.9634146341463414, 0.963855421686747, 0.9642857142857143, 0.9647058823529412, 0.9651162790697675, 0.9655172413793104, 0.9659090909090909, 0.9662921348314607, 0.9666666666666667, 0.967032967032967, 0.967391304347826, 0.967741935483871, 0.9680851063829787, 0.968421052631579, 0.96875, 0.9690721649484536, 0.9693877551020408, 0.9646464646464646]\n",
      "The best, most accurate K value for this set is 14\n"
     ]
    }
   ],
   "source": [
    "#Q20: What is the best value of k that you would suggest? \n",
    "#Hint: Use a for loop to test different values of k\n",
    "\n",
    "#kfold needs to start at at least 2 splits, cause logically it's not a split otherwise.\n",
    "testVal=2\n",
    "#list will populate with the accuracy values of the K folds\n",
    "averages=[]\n",
    "\n",
    "#while loop logic, testing k values [2,100] for the kfold\n",
    "while(testVal<100):\n",
    "    #run the kfold, called kfold2 just cuz second time we've done it this hw\n",
    "    kFold2= KFold(n_splits=testVal, random_state=42, shuffle=True)\n",
    "    #average the scores of the kfold of each k value\n",
    "    scores= cross_val_score(estimator=model, X=data.data, y=data.target, cv=kFold2)\n",
    "    avg= (sum(scores)/len(scores))\n",
    "    #add the averages to the list\n",
    "    averages.append(avg)\n",
    "    #increment the k value for the kfolding\n",
    "    testVal=testVal+1\n",
    "#print the averages\n",
    "print(averages)\n",
    "#find the max of the averages\n",
    "largest=max(averages)\n",
    "#the index of that maximum average, plus 2 because we started at k=2, is the most accurate k value.\n",
    "#averages[0] corrolates to a k value of 2 for instance\n",
    "bestK=averages.index(largest)+2\n",
    "print(\"The best, most accurate K value for this set is \" +str(bestK))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing the Best Estimator - For Graduate Students only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Phillip\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:976: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9555555555555556"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Q20: Compare knn, SVC(gamma='scale'), and GaussianNB() and display the prediction accuracies.\n",
    "#knn has already has its accuracy calculated, so only need to run the other 2.\n",
    "\n",
    "from sklearn.svm import LinearSVC #Linear support vector classification I presume? question not 100% clear\n",
    "\n",
    "#Need to use the same train_test_split from earlier\n",
    "#Just need to make a new classifier\n",
    "\n",
    "SVCclassifier= LinearSVC()\n",
    "SVCclassifier.fit(X_train,y_train)\n",
    "SVCpredictions= SVCclassifier.predict(X_test)\n",
    "SVCaccuracy= metrics.accuracy_score(y_test, SVCpredictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9777777777777777"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  # Gaussian naive Bayes classifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "GNBclassifier = GaussianNB()\n",
    "GNBclassifier.fit(X_train,y_train)\n",
    "GNBpredictions=GNBclassifier.predict(X_test)\n",
    "GNBaccuracy=metrics.accuracy_score(y_test, GNBpredictions)\n",
    "GNBaccuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gaussian naive Bayes classifier is the most accurate estimator for this dataset. Will likely not scale up well however, as a lazy learner like knn will take less system resources, especially if a large k value for k fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
