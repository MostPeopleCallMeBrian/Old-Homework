{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Create a TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is a beautiful day. Tomorrow looks like bad weather.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Today is a beautiful day. Tomorrow looks like bad weather.'\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TextBlob`, `Sentence`s and `Word`s Support String Methods and Comparisons \n",
    "* `Sentence`s, `Word`s and `TextBlob`s inherit from **`BaseBlob`**, which defines many common methods and properties\n",
    "* [**`BaseBlob` documentation**](https://textblob.readthedocs.io/en/dev/api_reference.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Tokenizing Text into Sentences and Words\n",
    "* Getting a list of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Phillip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Sentence(\"Today is a beautiful day.\"),\n",
       " Sentence(\"Tomorrow looks like bad weather.\")]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "blob.sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A `WordList` is a subclass of Python’s **built-in list type** with additional NLP methods. \n",
    "* Contains TextBlob `Word` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['Today', 'is', 'a', 'beautiful', 'day', 'Tomorrow', 'looks', 'like', 'bad', 'weather'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Parts-of-Speech Tagging\n",
    "\n",
    "* Evaluate words based on context to determine **parts of speech**, which can help determine meaning\n",
    "* Eight primary English parts of speech\n",
    "\t* **nouns**, **pronouns**, **verbs**, **adjectives**, **adverbs**, **prepositions**, **conjunctions** and **interjections** (words that express emotion and that are typically followed by **punctuation**, like “Yes!” or “Ha!”) \n",
    "    * Many subcategories \n",
    "* Some words have multiple meanings\n",
    "\t* E.g., “set” and “run” have **hundreds of meanings** each! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Phillip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Today', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('beautiful', 'JJ'),\n",
       " ('day', 'NN'),\n",
       " ('Tomorrow', 'NNP'),\n",
       " ('looks', 'VBZ'),\n",
       " ('like', 'IN'),\n",
       " ('bad', 'JJ'),\n",
       " ('weather', 'NN')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "blob.tags  #tags property returns list of tuples (word, string representing part-of-speech tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Parts-of-Speech Tagging (cont.)\n",
    "* `TextBlob` uses a `PatternTagger` to determine parts-of-speech\n",
    "* Uses [**pattern library**](https://www.clips.uantwerpen.be/pattern) POS tagging\n",
    "* Pattern's [63 parts-of-speech tags](https://www.clips.uantwerpen.be/pages/MBSP-tags`)\n",
    "* In preceding output:\n",
    "    * `NN`—a **singular noun** or **mass noun**\n",
    "    * `VBZ`—a [**third person singular present verb**](https://www.grammar.cl/Present/Verbs_Third_Person.htm)\n",
    "    * `DT`—a [**determiner**](https://en.wikipedia.org/wiki/Determiner) (the, an, that, this, my, their, etc.)\n",
    "    * `JJ`—an **adjective**\n",
    "    * `NNP`—a **proper singular noun**\n",
    "    * `IN`—a **subordinating conjunction** or **preposition**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Extracting Noun Phrases\n",
    "* Preparing to purchase a **water ski**\n",
    "* Might search for **“best water ski”**—**“water ski”** is a **noun phrase** \n",
    "* For best results, search engine must parse the noun phrase properly \n",
    "* Try searching for **“best water,”** **“best ski”**,  **“water ski”** and **“best water ski”** and see what you get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Phillip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\brown.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "WordList(['beautiful day', 'tomorrow', 'bad weather'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('brown')\n",
    "blob.noun_phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beautiful day\n",
      "tomorrow\n",
      "bad weather\n"
     ]
    }
   ],
   "source": [
    "for np in blob.noun_phrases:\n",
    "    print(np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* A **`Word`** can represent a noun phrase with **multiple words**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Sentiment Analysis with TextBlob’s Default Sentiment Analyzer\n",
    "* Determines whether text is **positive**, **neutral** or **negative**. \n",
    "* One of the most common and valuable NLP tasks (several later case studies do it) \n",
    "* Consider the **positive word “good”** and the **negative word “bad\"**\n",
    "    * Alone they are positive and negative, respectively, but...\n",
    "    * **The food is not good** — clearly has negative sentiment\n",
    "    * **The movie was not bad** — clearly has positive sentiment (but not as positive as **The movie was excellent!**)\n",
    "* Complex **machine-learning problem**, but libraries like TextBlob can do it for you"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Sentiment of a TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"Today is a beautiful day. Tomorrow looks like bad weather.\")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.07500000000000007, subjectivity=0.8333333333333333)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment # property showing whether text is +ve or -ve and whether it's objective or subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **`polarity`** is the **sentiment** — from **`-1.0` (negative)** to **`1.0` (positive)** with **`0.0`** being **neutral**. \n",
    "* **`subjectivity`** is a value from **0.0 (objective)** to **1.0 (subjective)**. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the polarity and subjectivity from the Sentiment Object\n",
    "* **`%precision`** magic specifies the **default precision** for **standalone** `float` objects and `float` objects in **built-in types** like lists, dictionaries and tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%.3f'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%precision 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.075"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Sentiment of a Sentence \n",
    "* One is **positive (`0.85`)** and one is **negative (`-0.6999999999999998`)**, which might explain why the entire `TextBlob`’s `sentiment` was close to **`0.0` (neutral)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(polarity=0.85, subjectivity=1.0)\n",
      "Sentiment(polarity=-0.6999999999999998, subjectivity=0.6666666666666666)\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Practice Q1. Import Sentence from TextBlob module then make Sentence objects to check the sentiments of the following statements.\n",
    "* \"The food is not good\"\n",
    "* \"The movie was not bad\"\n",
    "* \"The movie was Excellent\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=-0.35, subjectivity=0.6000000000000001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your Code here\n",
    "#Solution\n",
    "from textblob import Sentence\n",
    "Sentence('The food is not good.').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=0.3499999999999999, subjectivity=0.6666666666666666)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentence('The movie was not bad.').sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(polarity=1.0, subjectivity=1.0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sentence('The movie was Excellent.').sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Sentiment Analysis with the NaiveBayesAnalyzer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* By default, a TextBlob and the Sentences and Words we get from it determine sentiment using a PatternAnalyzer, which uses the sentiment analysis techniques in Pattern Library.\n",
    "* Naive Bayes - ML text-classification algorithm. \n",
    "* NaiveBayesAnalyzer (module textblob.sentiments), which was trained on a db of movie reviews.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob.sentiments import NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "text='The food is not good. The movie was not bad. The movie was excellent!'\n",
    "blob = TextBlob(text, analyzer=NaiveBayesAnalyzer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The food is not good. The movie was not bad. The movie was excellent!\")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Phillip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\movie_reviews.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.7318278242290406, p_neg=0.26817217577095936)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('movie_reviews')\n",
    "blob.sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment(classification='pos', p_pos=0.509829537403983, p_neg=0.4901704625960168)\n",
      "Sentiment(classification='neg', p_pos=0.31118417624529743, p_neg=0.6888158237547024)\n",
      "Sentiment(classification='pos', p_pos=0.7318278242290406, p_neg=0.26817217577095936)\n"
     ]
    }
   ],
   "source": [
    "for sentence in blob.sentences:\n",
    "    print(sentence.sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Practice Q2. Check the sentiment of the sentence 'The movie was excellent!' using NaiveBayesAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sentiment(classification='pos', p_pos=0.7318278242290406, p_neg=0.26817217577095936)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your Code here\n",
    "#Solution\n",
    "text = ('The movie was excellent!')\n",
    "exblob = TextBlob(text, analyzer=NaiveBayesAnalyzer())\n",
    "exblob.sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Language Detection and Translation\n",
    "* **Google Translate**, **Microsoft Bing Translator** and others can translate between scores of languages instantly\n",
    "* Now working on **near-real-time translation**\n",
    "    * Converse in real time with people who do not know your natural language\n",
    "* In the **IBM Watson** presentation, we'll develop a script that does **inter-language translation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish = blob.translate(to='es')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish.detect_language()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese = blob.translate(to='zh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese.detect_language()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Can **specify a source language** explicitly by passing the `from_lang` keyword argument to the `translate` method\n",
    "\n",
    "> ```python\n",
    "chinese = blob.translate(from_lang='en', to='zh')\n",
    "```\n",
    "\n",
    "* `from_lang` and `to` use [iso-639-1 language codes](https://en.wikipedia.org/wiki/List_of_ISO_639-1_codes)\n",
    "* [Google Translate’s list of supported languages](https://cloud.google.com/translate/docs/languages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spanish.translate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese.translate() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Note the slight difference in the English results.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Practice Q3. Translate 'The movie was excellent!' into French and detect the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Code here\n",
    "#Solution:\n",
    "blob = TextBlob('The movie was excellent!')\n",
    "french = blob.translate(to='fr')\n",
    "french"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "french.detect_language()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.8 Inflection: Pluralization and Singularization\n",
    "* Inflections are different forms of the same words, such as singular and plural (like “person” and “people”) and different verb tenses (like “run” and “ran”)\n",
    "* When you’re calculating word frequencies, you might first want to convert all inflected words to the same form for more accurate word frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = Word('index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'indices'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.pluralize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cacti = Word('cacti')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cactus'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cacti.singularize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Pluralizing and singularizing are not as simple as adding or removing an “s” or “es” at the end of a word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = TextBlob('dog cat fish bird').words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WordList(['dogs', 'cats', 'fish', 'birds'])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "animals.pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Practice Q3. Singularize the word 'children' and pluralize 'focus'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'child'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Your code here\n",
    "#Solution\n",
    "from textblob import Word\n",
    "Word('Children').singularize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'foci'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Word('focus').pluralize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.9 Spell Checking and Correction\n",
    "* For natural language processing tasks, it’s important that the text be free of spelling errors\n",
    "* A `Word`’s **`spellcheck` method** returns a list of tuples containing **possible correct spellings** and **confidence values**\n",
    "* Assume we meant to type “they” but misspelled it as “theyr”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = Word('theyr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('they', 0.571), ('their', 0.429)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.spellcheck()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'they'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.correct()  # chooses word with the highest confidence value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Word with the highest confidence value might not be the correct word for the given context\n",
    "* `TextBlob`s, `Sentence`s and `Word`s all have a `correct` method that you can call to correct spelling\n",
    "* Calling `correct` on a `Word` returns the correctly spelled word that has the highest confidence value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextBlob(\"The sentence has misspelled words to.\")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentence = TextBlob('Ths sentense has missplled wrds yo.')\n",
    "\n",
    "sentence.correct()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.10 Normalization: Stemming and Lemmatization\n",
    "* **Stemming** removes a **prefix** or **suffix** from a word leaving only a **stem**, which **may or may not be a real word**\n",
    "* **Lemmatization** is similar, but factors in the word’s **part of speech** and **meaning** and results in a **real word**\n",
    "* Both **normalize** words for analysis\n",
    "\t* Before calculating statistics on words in a body of text, you might convert all words to lowercase so that capitalized and lowercase words are not treated differently. \n",
    "* You might want to use a word’s root to represent the word’s many forms. \n",
    "\t* E.g., treat \"program\" and \"programs\" as \"program\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Phillip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import Word\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "word = Word('varieties')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'varieti'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.stem()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'variety'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word.lemmatize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: Before running this notebook, place a copy of your downloaded RomeoAndJuliet.txt file in the same folder with this notebook.**\n",
    "\n",
    "## 1.11 Word Frequencies\n",
    "* Various techniques for detecting **similarity between documents** rely on **word frequencies**\n",
    "* `TextBlob` can count word frequencies for you\n",
    "* When you read a file with `Path`’s `read_text` method, it closes the file immediately after it finishes reading the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(Path('RomeoAndJuliet.txt').read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Access the word frequencies through the `TextBlob`’s `word_counts` dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts['juliet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "299"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts['romeo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "277"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.word_counts['thou']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If you already have tokenized a `TextBlob` into a `WordList`, you can count specific words in the list via the `count` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.words.count('joy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.noun_phrases.count('lady capulet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.12 Deleting Stop Words\n",
    "* Common words that are often removed before analysis because they do not provide useful information\n",
    "* Returned by the NLTK `stopwords` module’s [`words` function](https://www.nltk.org/book/ch02.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| NLTK’s English stop words list\n",
    "| :---\n",
    "| `['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* NLTK has lists of stop words for several other natural languages as well\n",
    "* Before using, you must download them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Phillip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Today', 'beautiful', 'day']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stops = stopwords.words('english')\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "blob = TextBlob('Today is a beautiful day.')\n",
    "\n",
    "[word for word in blob.words if word not in stops]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.13 n-grams \n",
    "* [**n-gram**](https://en.wikipedia.org/wiki/N-gram) &mdash; a sequence of **n** text items, such as letters in words or words in a sentence. A form of co-occurence in which words or letters appear near each other in a body of text\n",
    "* Used to identify letters or words that frequently appear adjacent to one another\n",
    "    * **Predictive text input**\n",
    "    * **Speech-to-text**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Today is a beautiful day. Tomorrow looks like bad weather.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `TextBlob`’s `ngrams` method produces a list of `WordList` n-grams of length three by default—known as trigrams\n",
    "* Use keyword argument `n` to produce n-grams of any desired length\n",
    "* For speech-to-text n-grams help improve the quality of transcription."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Today', 'is', 'a']),\n",
       " WordList(['is', 'a', 'beautiful']),\n",
       " WordList(['a', 'beautiful', 'day']),\n",
       " WordList(['beautiful', 'day', 'Tomorrow']),\n",
       " WordList(['day', 'Tomorrow', 'looks']),\n",
       " WordList(['Tomorrow', 'looks', 'like']),\n",
       " WordList(['looks', 'like', 'bad']),\n",
       " WordList(['like', 'bad', 'weather'])]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['Today', 'is', 'a', 'beautiful', 'day']),\n",
       " WordList(['is', 'a', 'beautiful', 'day', 'Tomorrow']),\n",
       " WordList(['a', 'beautiful', 'day', 'Tomorrow', 'looks']),\n",
       " WordList(['beautiful', 'day', 'Tomorrow', 'looks', 'like']),\n",
       " WordList(['day', 'Tomorrow', 'looks', 'like', 'bad']),\n",
       " WordList(['Tomorrow', 'looks', 'like', 'bad', 'weather'])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.ngrams(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Visualizing Word Frequencies with Bar Charts and Word Clouds\n",
    "* Can enhance your corpus analyses\n",
    "    * A **bar chart** **quantitatively** visualizes the top n words in Romeo and Juliet as bars representing each word and its frequency.\n",
    "    * A **word cloud** **qualitatively** visualizes more frequently occurring words in larger fonts and less frequently occurring words in smaller fonts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Visualizing Word Frequencies with Pandas\n",
    "* Visualize **Romeo and Juliet**’s top 20 words that are **not stop words**, using features from **TextBlob**, **NLTK** and **pandas**. \n",
    "* Pandas visualization capabilities are based on Matplotlib, so launch IPython with the following command for this session:\n",
    ">```\n",
    "ipython --matplotlib\n",
    "```\n",
    "\n",
    "* Or enable matplotlib in Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = TextBlob(Path('RomeoAndJuliet.txt').read_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load NLTK stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Word Frequencies\n",
    "* Get word frequency tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = blob.word_counts.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminating the Stop Words\n",
    "* The expression `item[0]` gets the word from each tuple so we can check whether it’s in `stop_words`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = [item for item in items if item[0] not in stop_words]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting the Words by Frequency\n",
    "* Sort the tuples in items in descending order by frequency\n",
    "* To specify the tuple element to sort by, use the `itemgetter` function from the Python Standard Library’s `operator` module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('romeo', 299),\n",
       " ('thou', 277),\n",
       " ('juliet', 178),\n",
       " ('thy', 170),\n",
       " ('nurse', 149),\n",
       " ('capulet', 141),\n",
       " ('thee', 138),\n",
       " ('love', 137),\n",
       " ('shall', 110),\n",
       " ('lady', 109),\n",
       " ('friar', 104),\n",
       " ('come', 94),\n",
       " ('mercutio', 83),\n",
       " ('good', 81),\n",
       " ('benvolio', 79),\n",
       " ('enter', 75),\n",
       " ('go', 75),\n",
       " ('iâ€™ll', 71),\n",
       " ('tybalt', 70),\n",
       " ('death', 69),\n",
       " ('night', 68),\n",
       " ('lawrence', 67),\n",
       " ('man', 66),\n",
       " ('”', 65),\n",
       " ('hath', 64),\n",
       " ('one', 60),\n",
       " ('paris', 58),\n",
       " ('well', 58),\n",
       " ('sir', 57),\n",
       " ('art', 55),\n",
       " ('would', 54),\n",
       " ('say', 52),\n",
       " ('scene', 51),\n",
       " ('may', 48),\n",
       " ('dead', 48),\n",
       " ('doth', 47),\n",
       " ('give', 47),\n",
       " ('yet', 47),\n",
       " ('montague', 45),\n",
       " ('day', 45),\n",
       " ('fair', 44),\n",
       " ('let', 44),\n",
       " ('tell', 44),\n",
       " ('upon', 42),\n",
       " ('take', 40),\n",
       " ('â€™tis', 40),\n",
       " ('must', 40),\n",
       " ('â€', 40),\n",
       " ('make', 40),\n",
       " ('like', 38),\n",
       " ('prince', 37),\n",
       " ('much', 37),\n",
       " ('see', 36),\n",
       " ('know', 35),\n",
       " ('first', 34),\n",
       " ('exeunt', 34),\n",
       " ('sweet', 34),\n",
       " ('gone', 33),\n",
       " ('house', 32),\n",
       " ('exit', 32),\n",
       " ('time', 32),\n",
       " ('servant', 31),\n",
       " ('look', 31),\n",
       " ('ay', 30),\n",
       " ('us', 30),\n",
       " ('light', 30),\n",
       " ('lord', 30),\n",
       " ('wilt', 29),\n",
       " ('back', 29),\n",
       " ('mine', 29),\n",
       " ('heaven', 29),\n",
       " ('god', 29),\n",
       " ('old', 28),\n",
       " ('speak', 28),\n",
       " ('eyes', 28),\n",
       " ('hast', 28),\n",
       " ('word', 27),\n",
       " ('comes', 27),\n",
       " ('stay', 27),\n",
       " ('hence', 27),\n",
       " ('peter', 26),\n",
       " ('stand', 26),\n",
       " ('true', 26),\n",
       " ('heart', 26),\n",
       " ('bed', 25),\n",
       " ('hand', 25),\n",
       " ('dear', 25),\n",
       " ('young', 24),\n",
       " ('part', 24),\n",
       " ('find', 24),\n",
       " ('name', 24),\n",
       " ('life', 23),\n",
       " ('therefore', 23),\n",
       " ('away', 23),\n",
       " ('call', 23),\n",
       " ('madam', 23),\n",
       " ('die', 23),\n",
       " ('watch', 23),\n",
       " ('capuletâ€™s', 22),\n",
       " ('cell', 22),\n",
       " ('sampson', 22),\n",
       " ('men', 22),\n",
       " ('marry', 22),\n",
       " ('hear', 22),\n",
       " ('made', 22),\n",
       " ('till', 22),\n",
       " ('father', 22),\n",
       " ('lie', 21),\n",
       " ('ere', 21),\n",
       " ('bid', 21),\n",
       " ('think', 21),\n",
       " ('face', 21),\n",
       " ('holy', 21),\n",
       " ('wife', 20),\n",
       " ('two', 20),\n",
       " ('nay', 20),\n",
       " ('tears', 20),\n",
       " ('farewell', 20),\n",
       " ('balthasar', 19),\n",
       " ('cousin', 19),\n",
       " ('gregory', 19),\n",
       " ('live', 19),\n",
       " ('peace', 19),\n",
       " ('earth', 19),\n",
       " ('within', 19),\n",
       " ('lies', 19),\n",
       " ('eye', 19),\n",
       " ('married', 19),\n",
       " ('poor', 18),\n",
       " ('never', 18),\n",
       " ('help', 18),\n",
       " ('son', 17),\n",
       " ('blood', 17),\n",
       " ('could', 17),\n",
       " ('put', 17),\n",
       " ('grave', 17),\n",
       " ('hour', 17),\n",
       " ('pray', 17),\n",
       " ('lips', 17),\n",
       " ('slain', 17),\n",
       " ('banished', 17),\n",
       " ('place', 16),\n",
       " ('head', 16),\n",
       " ('keep', 16),\n",
       " ('long', 16),\n",
       " ('villain', 16),\n",
       " ('hold', 16),\n",
       " ('rest', 16),\n",
       " ('early', 16),\n",
       " ('romeoâ€™s', 16),\n",
       " ('county', 16),\n",
       " ('second', 16),\n",
       " ('mantua', 15),\n",
       " ('friend', 15),\n",
       " ('whose', 15),\n",
       " ('fear', 15),\n",
       " ('sun', 15),\n",
       " ('dost', 15),\n",
       " ('child', 15),\n",
       " ('world', 15),\n",
       " ('none', 15),\n",
       " ('mother', 15),\n",
       " ('alone', 15),\n",
       " ('tonight', 15),\n",
       " ('ah', 15),\n",
       " ('tomorrow', 15),\n",
       " ('news', 15),\n",
       " ('daughter', 14),\n",
       " ('run', 14),\n",
       " ('lives', 14),\n",
       " ('nothing', 14),\n",
       " ('many', 14),\n",
       " ('still', 14),\n",
       " ('said', 14),\n",
       " ('poison', 14),\n",
       " ('letter', 14),\n",
       " ('faith', 14),\n",
       " ('fall', 14),\n",
       " ('husband', 14),\n",
       " ('soul', 14),\n",
       " ('gentleman', 14),\n",
       " ('use', 14),\n",
       " ('joy', 14),\n",
       " ('breath', 14),\n",
       " ('haste', 14),\n",
       " ('thursday', 14),\n",
       " ('musician', 14),\n",
       " ('act', 13),\n",
       " ('chamber', 13),\n",
       " ('verona', 13),\n",
       " ('new', 13),\n",
       " ('hands', 13),\n",
       " ('ho', 13),\n",
       " ('came', 13),\n",
       " ('soon', 13),\n",
       " ('without', 13),\n",
       " ('thine', 13),\n",
       " ('else', 13),\n",
       " ('leave', 13),\n",
       " ('wit', 13),\n",
       " ('get', 13),\n",
       " ('woe', 13),\n",
       " ('thing', 13),\n",
       " ('little', 13),\n",
       " ('sin', 13),\n",
       " ('send', 13),\n",
       " ('ii', 12),\n",
       " ('iii', 12),\n",
       " ('kinsman', 12),\n",
       " ('page', 12),\n",
       " ('makes', 12),\n",
       " ('forth', 12),\n",
       " ('ever', 12),\n",
       " ('turn', 12),\n",
       " ('bear', 12),\n",
       " ('better', 12),\n",
       " ('talk', 12),\n",
       " ('hate', 12),\n",
       " ('happy', 12),\n",
       " ('gentle', 12),\n",
       " ('sleep', 12),\n",
       " ('grief', 12),\n",
       " ('ill', 12),\n",
       " ('sheâ€™s', 12),\n",
       " ('years', 12),\n",
       " ('even', 12),\n",
       " ('ye', 12),\n",
       " ('best', 12),\n",
       " ('â€™', 12),\n",
       " ('late', 12),\n",
       " ('hither', 12),\n",
       " ('shame', 12),\n",
       " ('julietâ€™s', 11),\n",
       " ('monument', 11),\n",
       " ('lay', 11),\n",
       " ('draw', 11),\n",
       " ('quarrel', 11),\n",
       " ('show', 11),\n",
       " ('law', 11),\n",
       " ('shalt', 11),\n",
       " ('beauty', 11),\n",
       " ('loveâ€™s', 11),\n",
       " ('heâ€™s', 11),\n",
       " ('oâ€™er', 11),\n",
       " ('though', 11),\n",
       " ('mad', 11),\n",
       " ('since', 11),\n",
       " ('warrant', 11),\n",
       " ('marriage', 11),\n",
       " ('pale', 11),\n",
       " ('alack', 11),\n",
       " ('bring', 11),\n",
       " ('street', 10),\n",
       " ('iv', 10),\n",
       " ('v', 10),\n",
       " ('lawrenceâ€™s', 10),\n",
       " ('john', 10),\n",
       " ('play', 10),\n",
       " ('ears', 10),\n",
       " ('weâ€™ll', 10),\n",
       " ('maid', 10),\n",
       " ('set', 10),\n",
       " ('saw', 10),\n",
       " ('heavy', 10),\n",
       " ('black', 10),\n",
       " ('hereâ€™s', 10),\n",
       " ('rich', 10),\n",
       " ('kiss', 10),\n",
       " ('comfort', 10),\n",
       " ('desperate', 10),\n",
       " ('master', 10),\n",
       " ('neâ€™er', 10),\n",
       " ('calls', 10),\n",
       " ('need', 10),\n",
       " ('done', 10),\n",
       " ('dream', 10),\n",
       " ('flower', 10),\n",
       " ('every', 10),\n",
       " ('another', 10),\n",
       " ('straight', 10),\n",
       " ('gentlemen', 10),\n",
       " ('boy', 10),\n",
       " ('twenty', 10),\n",
       " ('kill', 10),\n",
       " ('says', 10),\n",
       " ('answer', 10),\n",
       " ('pardon', 10),\n",
       " ('tongue', 10),\n",
       " ('full', 10),\n",
       " ('church', 10),\n",
       " ('tybaltâ€™s', 10),\n",
       " ('open', 9),\n",
       " ('churchyard', 9),\n",
       " ('apothecary', 9),\n",
       " ('musicians', 9),\n",
       " ('ancient', 9),\n",
       " ('end', 9),\n",
       " ('move', 9),\n",
       " ('wall', 9),\n",
       " ('foot', 9),\n",
       " ('ground', 9),\n",
       " ('case', 9),\n",
       " ('either', 9),\n",
       " ('means', 9),\n",
       " ('weep', 9),\n",
       " ('forget', 9),\n",
       " ('unto', 9),\n",
       " ('way', 9),\n",
       " ('hide', 9),\n",
       " ('rosaline', 9),\n",
       " ('indeed', 9),\n",
       " ('great', 9),\n",
       " ('days', 9),\n",
       " ('thus', 9),\n",
       " ('others', 9),\n",
       " ('whatâ€™s', 9),\n",
       " ('body', 9),\n",
       " ('vault', 9),\n",
       " ('room', 8),\n",
       " ('hall', 8),\n",
       " ('garden', 8),\n",
       " ('capulets', 8),\n",
       " ('three', 8),\n",
       " ('bite', 8),\n",
       " ('sword', 8),\n",
       " ('mind', 8),\n",
       " ('clouds', 8),\n",
       " ('counsel', 8),\n",
       " ('noble', 8),\n",
       " ('alas', 8),\n",
       " ('mistress', 8),\n",
       " ('bound', 8),\n",
       " ('welcome', 8),\n",
       " ('last', 8),\n",
       " ('merry', 8),\n",
       " ('ladyâ€™s', 8),\n",
       " ('sight', 8),\n",
       " ('enough', 8),\n",
       " ('torch', 8),\n",
       " ('thatâ€™s', 8),\n",
       " ('times', 8),\n",
       " ('things', 8),\n",
       " ('menâ€™s', 8),\n",
       " ('vile', 8),\n",
       " ('swear', 8),\n",
       " ('saint', 8),\n",
       " ('meet', 8),\n",
       " ('high', 8),\n",
       " ('sound', 8),\n",
       " ('sorrow', 8),\n",
       " ('woes', 8),\n",
       " ('bones', 8),\n",
       " ('hie', 8),\n",
       " ('thought', 8),\n",
       " ('abram', 7),\n",
       " ('servants', 7),\n",
       " ('fearful', 7),\n",
       " ('mean', 7),\n",
       " ('shows', 7),\n",
       " ('feel', 7),\n",
       " ('flesh', 7),\n",
       " ('noise', 7),\n",
       " ('fire', 7),\n",
       " ('bloody', 7),\n",
       " ('found', 7),\n",
       " ('morning', 7),\n",
       " ('air', 7),\n",
       " ('short', 7),\n",
       " ('cold', 7),\n",
       " ('sick', 7),\n",
       " ('sea', 7),\n",
       " ('near', 7),\n",
       " ('hit', 7),\n",
       " ('canst', 7),\n",
       " ('behold', 7),\n",
       " ('stars', 7),\n",
       " ('dark', 7),\n",
       " ('gives', 7),\n",
       " ('writ', 7),\n",
       " ('fortune', 7),\n",
       " ('book', 7),\n",
       " ('thousand', 7),\n",
       " ('beseech', 7),\n",
       " ('follow', 7),\n",
       " ('measure', 7),\n",
       " ('tender', 7),\n",
       " ('anon', 7),\n",
       " ('ear', 7),\n",
       " ('bosom', 7),\n",
       " ('music', 7),\n",
       " ('hot', 7),\n",
       " ('sit', 7),\n",
       " ('past', 7),\n",
       " ('fetch', 7),\n",
       " ('honest', 7),\n",
       " ('looks', 7),\n",
       " ('thyself', 7),\n",
       " ('words', 7),\n",
       " ('murder', 7),\n",
       " ('silver', 7),\n",
       " ('sudden', 7),\n",
       " ('next', 7),\n",
       " ('tomb', 7),\n",
       " ('killâ€™d', 7),\n",
       " ('corse', 7),\n",
       " ('woeful', 7),\n",
       " ('dagger', 7),\n",
       " ('chorus', 6),\n",
       " ('montagues', 6),\n",
       " ('citizens', 6),\n",
       " ('oâ€™', 6),\n",
       " ('moved', 6),\n",
       " ('stir', 6),\n",
       " ('maids', 6),\n",
       " ('hadst', 6),\n",
       " ('thumb', 6),\n",
       " ('side', 6),\n",
       " ('serve', 6),\n",
       " ('remember', 6),\n",
       " ('fight', 6),\n",
       " ('among', 6),\n",
       " ('close', 6),\n",
       " ('hurt', 6),\n",
       " ('might', 6),\n",
       " ('seen', 6),\n",
       " ('deep', 6),\n",
       " ('home', 6),\n",
       " ('prove', 6),\n",
       " ('unless', 6),\n",
       " ('envious', 6),\n",
       " ('aside', 6),\n",
       " ('letâ€™s', 6),\n",
       " ('morrow', 6),\n",
       " ('hours', 6),\n",
       " ('loving', 6),\n",
       " ('lead', 6),\n",
       " ('breast', 6),\n",
       " ('mark', 6),\n",
       " ('dies', 6),\n",
       " ('read', 6),\n",
       " ('fourteen', 6),\n",
       " ('bride', 6),\n",
       " ('feast', 6),\n",
       " ('sirrah', 6),\n",
       " ('whereâ€™s', 6),\n",
       " ('girl', 6),\n",
       " ('matter', 6),\n",
       " ('age', 6),\n",
       " ('fool', 6),\n",
       " ('took', 6),\n",
       " ('jest', 6),\n",
       " ('wast', 6),\n",
       " ('wish', 6),\n",
       " ('less', 6),\n",
       " ('strength', 6),\n",
       " ('five', 6),\n",
       " ('spoke', 6),\n",
       " ('care', 6),\n",
       " ('tale', 6),\n",
       " ('yonder', 6),\n",
       " ('cheek', 6),\n",
       " ('youth', 6),\n",
       " ('thank', 6),\n",
       " ('enemy', 6),\n",
       " ('strange', 6),\n",
       " ('kind', 6),\n",
       " ('speaks', 6),\n",
       " ('arm', 6),\n",
       " ('stop', 6),\n",
       " ('didst', 6),\n",
       " ('re-enter', 6),\n",
       " ('company', 6),\n",
       " ('flowers', 6),\n",
       " ('cheeks', 6),\n",
       " ('goose', 6),\n",
       " ('cords', 6),\n",
       " ('fie', 6),\n",
       " ('princeâ€™s', 6),\n",
       " ('doom', 6),\n",
       " ('exile', 6),\n",
       " ('banishment', 6),\n",
       " ('lark', 6),\n",
       " ('proud', 6),\n",
       " ('public', 5),\n",
       " ('women', 5),\n",
       " ('houses', 5),\n",
       " ('break', 5),\n",
       " ('civil', 5),\n",
       " ('piteous', 5),\n",
       " ('swords', 5),\n",
       " ('strike', 5),\n",
       " ('quickly', 5),\n",
       " ('dog', 5),\n",
       " ('heads', 5),\n",
       " ('pretty', 5),\n",
       " ('dare', 5),\n",
       " ('hell', 5),\n",
       " ('foe', 5),\n",
       " ('pleasure', 5),\n",
       " ('withal', 5),\n",
       " ('scorn', 5),\n",
       " ('right', 5),\n",
       " ('sighs', 5),\n",
       " ('cause', 5),\n",
       " ('friends', 5),\n",
       " ('far', 5),\n",
       " ('shrift', 5),\n",
       " ('nine', 5),\n",
       " ('sad', 5),\n",
       " ('rough', 5),\n",
       " ('bright', 5),\n",
       " ('loversâ€™', 5),\n",
       " ('going', 5),\n",
       " ('soft', 5),\n",
       " ('gold', 5),\n",
       " ('wise', 5),\n",
       " ('wisely', 5),\n",
       " ('blind', 5),\n",
       " ('honourable', 5),\n",
       " ('change', 5),\n",
       " ('consent', 5),\n",
       " ('voice', 5),\n",
       " ('written', 5),\n",
       " ('fellow', 5),\n",
       " ('letters', 5),\n",
       " ('brother', 5),\n",
       " ('laid', 5),\n",
       " ('quoth', 5),\n",
       " ('grace', 5),\n",
       " ('honour', 5),\n",
       " ('already', 5),\n",
       " ('brief', 5),\n",
       " ('excuse', 5),\n",
       " ('dance', 5),\n",
       " ('wings', 5),\n",
       " ('rude', 5),\n",
       " ('wits', 5),\n",
       " ('ask', 5),\n",
       " ('asleep', 5),\n",
       " ('shape', 5),\n",
       " ('half', 5),\n",
       " ('state', 5),\n",
       " ('fingers', 5),\n",
       " ('dreams', 5),\n",
       " ('nightâ€™s', 5),\n",
       " ('untimely', 5),\n",
       " ('ready', 5),\n",
       " ('longer', 5),\n",
       " ('isâ€™t', 5),\n",
       " ('blessed', 5),\n",
       " ('wherefore', 5),\n",
       " ('patience', 5),\n",
       " ('prepare', 5),\n",
       " ('yond', 5),\n",
       " ('heir', 5),\n",
       " ('wedding', 5),\n",
       " ('power', 5),\n",
       " ('satisfied', 5),\n",
       " ('return', 5),\n",
       " ('tear', 5),\n",
       " ('fain', 5),\n",
       " ('form', 5),\n",
       " ('trust', 5),\n",
       " ('manâ€™s', 5),\n",
       " ('ring', 5),\n",
       " ('thereâ€™s', 5),\n",
       " ('chide', 5),\n",
       " ('sure', 5),\n",
       " ('lamentable', 5),\n",
       " ('hare', 5),\n",
       " ('commend', 5),\n",
       " ('joyful', 5),\n",
       " ('lawrenceâ€™', 5),\n",
       " ('simple', 5),\n",
       " ('reason', 5),\n",
       " ('mercutioâ€™s', 5),\n",
       " ('falls', 5),\n",
       " ('slew', 5),\n",
       " ('slay', 5),\n",
       " ('point', 5),\n",
       " ('mercy', 5),\n",
       " ('living', 5),\n",
       " ('ha', 5),\n",
       " ('hang', 5),\n",
       " ('drink', 5),\n",
       " ('wake', 5),\n",
       " ('attendants', 4),\n",
       " ('fatal', 4),\n",
       " ('rage', 4),\n",
       " ('remove', 4),\n",
       " ('weak', 4),\n",
       " ('fought', 4),\n",
       " ('cut', 4),\n",
       " ('known', 4),\n",
       " ('begin', 4),\n",
       " ('kinsmen', 4),\n",
       " ('beats', 4),\n",
       " ('beat', 4),\n",
       " ('spite', 4),\n",
       " ('seek', 4),\n",
       " ('steel', 4),\n",
       " ('veins', 4),\n",
       " ('torture', 4),\n",
       " ('quiet', 4),\n",
       " ('streets', 4),\n",
       " ('pay', 4),\n",
       " ('depart', 4),\n",
       " ('along', 4),\n",
       " ('fray', 4),\n",
       " ('golden', 4),\n",
       " ('window', 4),\n",
       " ('east', 4),\n",
       " ('walk', 4),\n",
       " ('city', 4),\n",
       " ('towards', 4),\n",
       " ('sought', 4),\n",
       " ('morningâ€™s', 4),\n",
       " ('dew', 4),\n",
       " ('daylight', 4),\n",
       " ('uncle', 4),\n",
       " ('secret', 4),\n",
       " ('sadness', 4),\n",
       " ('anything', 4),\n",
       " ('coz', 4),\n",
       " ('rather', 4),\n",
       " ('griefs', 4),\n",
       " ('tut', 4),\n",
       " ('forsworn', 4),\n",
       " ('vow', 4),\n",
       " ('note', 4),\n",
       " ('woo', 4),\n",
       " ('names', 4),\n",
       " ('shut', 4),\n",
       " ('signior', 4),\n",
       " ('supper', 4),\n",
       " ('thither', 4),\n",
       " ('match', 4),\n",
       " ('lamb', 4),\n",
       " ('awhile', 4),\n",
       " ('bitter', 4),\n",
       " ('brow', 4),\n",
       " ('left', 4),\n",
       " ('stands', 4),\n",
       " ('wisdom', 4),\n",
       " ('count', 4),\n",
       " ('lover', 4),\n",
       " ('fly', 4),\n",
       " ('guests', 4),\n",
       " ('believe', 4),\n",
       " ('mask', 4),\n",
       " ('save', 4),\n",
       " ('empty', 4),\n",
       " ('kisses', 4),\n",
       " ('oft', 4),\n",
       " ('foul', 4),\n",
       " ('course', 4),\n",
       " ('deny', 4),\n",
       " ('worn', 4),\n",
       " ('dares', 4),\n",
       " ('truth', 4),\n",
       " ('town', 4),\n",
       " ('youâ€™ll', 4),\n",
       " ('lest', 4),\n",
       " ('sake', 4),\n",
       " ('door', 4),\n",
       " ('birth', 4),\n",
       " ('ran', 4),\n",
       " ('conjure', 4),\n",
       " ('cry', 4),\n",
       " ('fine', 4),\n",
       " ('anger', 4),\n",
       " ('raise', 4),\n",
       " ('spirit', 4),\n",
       " ('nature', 4),\n",
       " ('tree', 4),\n",
       " ('moon', 4),\n",
       " ('green', 4),\n",
       " ('wear', 4),\n",
       " ('bold', 4),\n",
       " ('hateful', 4),\n",
       " ('lent', 4),\n",
       " ('lightning', 4),\n",
       " ('gave', 4),\n",
       " ('adieu', 4),\n",
       " ('ghostly', 4),\n",
       " ('dry', 4),\n",
       " ('womb', 4),\n",
       " ('keeps', 4),\n",
       " ('met', 4),\n",
       " ('slow', 4),\n",
       " ('wench', 4),\n",
       " ('broad', 4),\n",
       " ('hair', 4),\n",
       " ('gentlewoman', 4),\n",
       " ('fault', 4),\n",
       " ('iâ€™faith', 4),\n",
       " ('something', 4),\n",
       " ('hoar', 4),\n",
       " ('minute', 4),\n",
       " ('knave', 4),\n",
       " ('hark', 4),\n",
       " ('knife', 4),\n",
       " ('warm', 4),\n",
       " ('sour', 4),\n",
       " ('beshrew', 4),\n",
       " ('amen', 4),\n",
       " ('work', 4),\n",
       " ('beg', 4),\n",
       " ('loss', 4),\n",
       " ('slaughterâ€™d', 4),\n",
       " ('damned', 4),\n",
       " ('weeping', 4),\n",
       " ('banishâ€™d', 4),\n",
       " ('knocking', 4),\n",
       " ('search', 4),\n",
       " ('weeps', 4),\n",
       " ('coming', 4),\n",
       " ('doubt', 4),\n",
       " ('nightly', 4),\n",
       " ('hope', 4),\n",
       " ('bridegroom', 4),\n",
       " ('needs', 4),\n",
       " ('buried', 4),\n",
       " ('â€˜heartâ€™s', 4),\n",
       " ('iron', 4),\n",
       " ('soundâ€™', 4),\n",
       " ('sell', 4),\n",
       " ('strew', 4),\n",
       " ('intents', 4),\n",
       " ('prologue', 3),\n",
       " ('belonging', 3),\n",
       " ('nephew', 3),\n",
       " ('order', 3),\n",
       " ('maskers', 3),\n",
       " ('alike', 3),\n",
       " ('lovers', 3),\n",
       " ('bury', 3),\n",
       " ('strife', 3),\n",
       " ('patient', 3),\n",
       " ('attend', 3),\n",
       " ('toil', 3),\n",
       " ('slave', 3),\n",
       " ('goes', 3),\n",
       " ('thrust', 3),\n",
       " ('sense', 3),\n",
       " ('pass', 3),\n",
       " ('drawn', 3),\n",
       " ('citizen', 3),\n",
       " ('pain', 3),\n",
       " ('airy', 3),\n",
       " ('cast', 3),\n",
       " ('afternoon', 3),\n",
       " ('approach', 3),\n",
       " ('blows', 3),\n",
       " ('today', 3),\n",
       " ('abroad', 3),\n",
       " ('humour', 3),\n",
       " ('learn', 3),\n",
       " ('grow', 3),\n",
       " ('cure', 3),\n",
       " ('please', 3),\n",
       " ('wert', 3),\n",
       " ('fast', 3),\n",
       " ('view', 3),\n",
       " ('proof', 3),\n",
       " ('laugh', 3),\n",
       " ('heartâ€™s', 3),\n",
       " ('oppression', 3),\n",
       " ('lost', 3),\n",
       " ('urgâ€™d', 3),\n",
       " ('woman', 3),\n",
       " ('lovâ€™d', 3),\n",
       " ('strong', 3),\n",
       " ('bow', 3),\n",
       " ('sworn', 3),\n",
       " ('waste', 3),\n",
       " ('making', 3),\n",
       " ('rulâ€™d', 3),\n",
       " ('teach', 3),\n",
       " ('liberty', 3),\n",
       " ('beauties', 3),\n",
       " ('precious', 3),\n",
       " ('hard', 3),\n",
       " ('suit', 3),\n",
       " ('delight', 3),\n",
       " ('paper', 3),\n",
       " ('anotherâ€™s', 3),\n",
       " ('backward', 3),\n",
       " ('food', 3),\n",
       " ('cup', 3),\n",
       " ('compare', 3),\n",
       " ('crow', 3),\n",
       " ('year', 3),\n",
       " ('forbid', 3),\n",
       " ('daughterâ€™s', 3),\n",
       " ('susan', 3),\n",
       " ('dug', 3),\n",
       " ('brain', 3),\n",
       " ('taste', 3),\n",
       " ('â€™twas', 3),\n",
       " ('jule', 3),\n",
       " ('wretch', 3),\n",
       " ('â€˜ayâ€™', 3),\n",
       " ('choose', 3),\n",
       " ('knock', 3),\n",
       " ('ladies', 3),\n",
       " ('parisâ€™', 3),\n",
       " ('lends', 3),\n",
       " ('content', 3),\n",
       " ('cursed', 3),\n",
       " ('date', 3),\n",
       " ('cupid', 3),\n",
       " ('burden', 3),\n",
       " ('visor', 3),\n",
       " ('blush', 3),\n",
       " ('mouse', 3),\n",
       " ('burn', 3),\n",
       " ('delay', 3),\n",
       " ('vain', 3),\n",
       " ('meaning', 3),\n",
       " ('dreamt', 3),\n",
       " ('mab', 3),\n",
       " ('knees', 3),\n",
       " ('sometime', 3),\n",
       " ('wakes', 3),\n",
       " ('substance', 3),\n",
       " ('wind', 3),\n",
       " ('closâ€™d', 3),\n",
       " ('loves', 3),\n",
       " ('fellows', 3),\n",
       " ('solemnity', 3),\n",
       " ('virtuous', 3),\n",
       " ('chance', 3),\n",
       " ('contrary', 3),\n",
       " ('hearts', 3),\n",
       " ('withdraw', 3),\n",
       " ('seeming', 3),\n",
       " ('touch', 3),\n",
       " ('saints', 3),\n",
       " ('craves', 3),\n",
       " ('passion', 3),\n",
       " ('appear', 3),\n",
       " ('likeness', 3),\n",
       " ('pronounce', 3),\n",
       " ('mistressâ€™', 3),\n",
       " ('hid', 3),\n",
       " ('wound', 3),\n",
       " ('arise', 3),\n",
       " ('knew', 3),\n",
       " ('business', 3),\n",
       " ('gaze', 3),\n",
       " ('hundred', 3),\n",
       " ('walls', 3),\n",
       " ('washâ€™d', 3),\n",
       " ('dwell', 3),\n",
       " ('mayst', 3),\n",
       " ('fond', 3),\n",
       " ('confess', 3),\n",
       " ('cease', 3),\n",
       " ('faithful', 3),\n",
       " ('purpose', 3),\n",
       " ('worse', 3),\n",
       " ('toward', 3),\n",
       " ('almost', 3),\n",
       " ('morn', 3),\n",
       " ('dayâ€™s', 3),\n",
       " ('turns', 3),\n",
       " ('lo', 3),\n",
       " ('confession', 3),\n",
       " ('truly', 3),\n",
       " ('jesu', 3),\n",
       " ('pure', 3),\n",
       " ('devil', 3),\n",
       " ('fatherâ€™s', 3),\n",
       " ('third', 3),\n",
       " ('immortal', 3),\n",
       " ('flies', 3),\n",
       " ('courtesy', 3),\n",
       " ('courteous', 3),\n",
       " ('faint', 3),\n",
       " ('whole', 3),\n",
       " ('wide', 3),\n",
       " ('wouldst', 3),\n",
       " ('good-den', 3),\n",
       " ('bawd', 3),\n",
       " ('spent', 3),\n",
       " ('sings', 3),\n",
       " ('meat', 3),\n",
       " ('dinner', 3),\n",
       " ('occasion', 3),\n",
       " ('afore', 3),\n",
       " ('told', 3),\n",
       " ('protest', 3),\n",
       " ('devise', 3),\n",
       " ('sayâ€™st', 3),\n",
       " ('sweetest', 3),\n",
       " ('toad', 3),\n",
       " ('rosemary', 3),\n",
       " ('thoughts', 3),\n",
       " ('youthful', 3),\n",
       " ('swift', 3),\n",
       " ('honey', 3),\n",
       " ('bad', 3),\n",
       " ('godâ€™s', 3),\n",
       " ('got', 3),\n",
       " ('heavens', 3),\n",
       " ('powder', 3),\n",
       " ('loathsome', 3),\n",
       " ('thanks', 3),\n",
       " ('lain', 3),\n",
       " ('apt', 3),\n",
       " ('buy', 3),\n",
       " ('consort', 3),\n",
       " ('discords', 3),\n",
       " ('afford', 3),\n",
       " ('knowâ€™st', 3),\n",
       " ('calm', 3),\n",
       " ('plague', 3),\n",
       " ('scratch', 3),\n",
       " ('mortal', 3),\n",
       " ('fury', 3),\n",
       " ('conduct', 3),\n",
       " ('wretched', 3),\n",
       " ('murderer', 3),\n",
       " ('charge', 3),\n",
       " ('deadly', 3),\n",
       " ('cries', 3),\n",
       " ('toâ€™t', 3),\n",
       " ('modesty', 3),\n",
       " ('bare', 3),\n",
       " ('fiend', 3),\n",
       " ('born', 3),\n",
       " ('beast', 3),\n",
       " ('murderâ€™d', 3),\n",
       " ('beguilâ€™d', 3),\n",
       " ('tidings', 3),\n",
       " ('philosophy', 3),\n",
       " ('deathâ€™s', 3),\n",
       " ('wild', 3),\n",
       " ('hollow', 3),\n",
       " ('rouse', 3),\n",
       " ('stayâ€™d', 3),\n",
       " ('wednesday', 3),\n",
       " ('nightingale', 3),\n",
       " ('methinks', 3),\n",
       " ('fickle', 3),\n",
       " ('unaccustomâ€™d', 3),\n",
       " ('cousinâ€™s', 3),\n",
       " ('needy', 3),\n",
       " ('peterâ€™s', 3),\n",
       " ('wed', 3),\n",
       " ('bark', 3),\n",
       " ('joints', 3),\n",
       " ('bridal', 3),\n",
       " ('remedy', 3),\n",
       " ('hearâ€™st', 3),\n",
       " ('presently', 3),\n",
       " ('present', 3),\n",
       " ('shroud', 3),\n",
       " ('meantime', 3),\n",
       " ('waking', 3),\n",
       " ('speed', 3),\n",
       " ('hire', 3),\n",
       " ('lick', 3),\n",
       " ('knows', 3),\n",
       " ('logs', 3),\n",
       " ('cruel', 3),\n",
       " ('aloof', 3),\n",
       " ('retires', 3),\n",
       " ('mattock', 3),\n",
       " ('apprehend', 3),\n",
       " ('adjoining', 2),\n",
       " ('vi', 2),\n",
       " ('gallery', 2),\n",
       " ('overlooking', 2),\n",
       " ('escalus', 2),\n",
       " ('nobleman', 2),\n",
       " ('veronese', 2),\n",
       " ('family', 2),\n",
       " ('feud', 2),\n",
       " ('franciscan', 2),\n",
       " ('greater', 2),\n",
       " ('mutiny', 2),\n",
       " ('pair', 2),\n",
       " ('parentsâ€™', 2),\n",
       " ('miss', 2),\n",
       " ('mend', 2),\n",
       " ('carry', 2),\n",
       " ('choler', 2),\n",
       " ('neck', 2),\n",
       " ('valiant', 2),\n",
       " ('montagueâ€™s', 2),\n",
       " ('tyrant', 2),\n",
       " ('able', 2),\n",
       " ('piece', 2),\n",
       " ('fish', 2),\n",
       " ('weapon', 2),\n",
       " ('frown', 2),\n",
       " ('masterâ€™s', 2),\n",
       " ('yes', 2),\n",
       " ...]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_items = sorted(items, key=itemgetter(1), reverse=True) #access elements at index 1 in each tuple\n",
    "sorted_items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Top 20 Words\n",
    "* `TextBlob` tokenizaton splits all **contractions** at their **apostrophes** and **counts** the total number of **apostrophes** as one of the “words” \n",
    "* **Romeo and Juliet** has many contractions\n",
    "    * If you display `sorted_items[0]`, you’ll see that they are the most frequently occurring “word” with `867` of them\n",
    "    * (In some **locales** this does not happen and element 0 is indeed `'romeo'`) \n",
    "    * We ignore element `0` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "top20 = sorted_items[1:21]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert top20 to a DataFrame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(top20, columns=['word', 'count'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thou</td>\n",
       "      <td>277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>juliet</td>\n",
       "      <td>178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thy</td>\n",
       "      <td>170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nurse</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>capulet</td>\n",
       "      <td>141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>thee</td>\n",
       "      <td>138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>love</td>\n",
       "      <td>137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>shall</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>lady</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>friar</td>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>come</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>mercutio</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>good</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>benvolio</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>enter</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>go</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>iâ€™ll</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>tybalt</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>death</td>\n",
       "      <td>69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>night</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        word  count\n",
       "0       thou    277\n",
       "1     juliet    178\n",
       "2        thy    170\n",
       "3      nurse    149\n",
       "4    capulet    141\n",
       "5       thee    138\n",
       "6       love    137\n",
       "7      shall    110\n",
       "8       lady    109\n",
       "9      friar    104\n",
       "10      come     94\n",
       "11  mercutio     83\n",
       "12      good     81\n",
       "13  benvolio     79\n",
       "14     enter     75\n",
       "15        go     75\n",
       "16    iâ€™ll     71\n",
       "17    tybalt     70\n",
       "18     death     69\n",
       "19     night     68"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the DataFrame \n",
    "* **`bar` method** of the `DataFrame`’s **`plot` property** creates and displays a **Matplotlib bar chart**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "axes = df.plot.bar(x='word', y='count', legend=False)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Visualizing Word Frequencies with Word Clouds \n",
    "* (Word cloud: graphic that shows more frequently occuring words in bigger fonts and less frequently occuring words in smllaer fonts)\n",
    "* Open source [**`wordcloud` module’s**](https://github.com/amueller/word_cloud) **`WordCloud` class** \n",
    "* Uses matplotlib under the hood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installing the wordcloud Module\n",
    "* `conda install -c conda-forge wordcloud`\n",
    "    * Windows users should **run the Anaconda Prompt as an Administrator**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = Path('RomeoAndJuliet.txt').read_text()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Mask Image that Specifies the Word Cloud’s Shape\n",
    "* `WordCloud` fills non-white areas of a mask image with text\n",
    "* Load the mask using the **`imread` function** from the `imageio` module that comes with Anaconda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "No such file: 'C:\\Users\\Phillip\\mask_heart.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-dd8b9dcf339d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmask_image\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimageio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mask_heart.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mimread\u001b[1;34m(uri, format, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m     \u001b[1;31m# Get reader and read first\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m     \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"i\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\functions.py\u001b[0m in \u001b[0;36mget_reader\u001b[1;34m(uri, format, mode, **kwargs)\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# Create request object\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 172\u001b[1;33m     \u001b[0mrequest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m     \u001b[1;31m# Get format\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, uri, mode, **kwargs)\u001b[0m\n\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m         \u001b[1;31m# Parse what was given\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parse_uri\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muri\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m         \u001b[1;31m# Set extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\imageio\\core\\request.py\u001b[0m in \u001b[0;36m_parse_uri\u001b[1;34m(self, uri)\u001b[0m\n\u001b[0;32m    258\u001b[0m                 \u001b[1;31m# Reading: check that the file exists (but is allowed a dir)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 260\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file: '%s'\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    261\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    262\u001b[0m                 \u001b[1;31m# Writing: check that the directory to write to does exist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: No such file: 'C:\\Users\\Phillip\\mask_heart.png'"
     ]
    }
   ],
   "source": [
    "mask_image = imageio.imread('mask_heart.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the WordCloud Object\n",
    "* 400-by-200 pixels, unless you specify **`width`** and **`height`**\n",
    "* If you specify a mask image without `width` and `height`, `WordCloud` uses the image’s size\n",
    "* `WordCloud` assigns **random colors** from a **color map**\n",
    "* [Matplotlib’s named color maps](https://matplotlib.org/examples/color/colormaps_reference.html)\n",
    "* [Complete list of `WordCloud`’s keyword arguments](http://amueller.github.io/word_cloud/generated/wordcloud.WordCloud.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = WordCloud(width=1000, height=1000, \n",
    "    colormap='prism', mask=mask_image, background_color='white')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the Word Cloud\n",
    "* `WordCloud`’s `generate` method receives the text to use in the word cloud as an argument and creates the word cloud, which it returns as a `WordCloud` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = wordcloud.generate(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **removes stop words** from the `text` argument, using the `wordcloud` module’s built-in stop-words list\n",
    "* **calculates the word frequencies** for the remaining words\n",
    "* **builds the cloud** with a **maximum of 200 words by default**, but can specify **`max_words` keyword argument**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Word Cloud as an Image File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud = wordcloud.to_file('RomeoAndJulietHeart.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating a Word Cloud from a Dictionary\n",
    "* If you have a dictionary of word counts, `WordCloud`’s **`fit_words` method** can create a word cloud from it, but does not remove the stop words from the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the Image with Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(wordcloud)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![RomeoAndJulietHeart.png](./RomeoAndJulietHeart.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Practice Q2. Generate a word cloud of star mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
